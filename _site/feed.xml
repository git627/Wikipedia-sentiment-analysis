<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/Wikipedia-sentiment-analysis/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/Wikipedia-sentiment-analysis/" rel="alternate" type="text/html" /><updated>2025-10-07T16:39:54-04:00</updated><id>http://localhost:4000/Wikipedia-sentiment-analysis/feed.xml</id><title type="html">Wikipedia Sentiment Analysis</title><subtitle>This site presents discussion and use cases of the Wikipedia-sentiment-analysis repository found at https://github.com/git627/Wikipedia-sentiment-analysis.</subtitle><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/Wikipedia-sentiment-analysis/jekyll/update/2025/10/07/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2025-10-07T13:09:08-04:00</published><updated>2025-10-07T13:09:08-04:00</updated><id>http://localhost:4000/Wikipedia-sentiment-analysis/jekyll/update/2025/10/07/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/Wikipedia-sentiment-analysis/jekyll/update/2025/10/07/welcome-to-jekyll.html"><![CDATA[<p>You’ll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<p>Jekyll requires blog post files to be named according to the following format:</p>

<p><code class="language-plaintext highlighter-rouge">YEAR-MONTH-DAY-title.MARKUP</code></p>

<p>Where <code class="language-plaintext highlighter-rouge">YEAR</code> is a four-digit number, <code class="language-plaintext highlighter-rouge">MONTH</code> and <code class="language-plaintext highlighter-rouge">DAY</code> are both two-digit numbers, and <code class="language-plaintext highlighter-rouge">MARKUP</code> is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span></code></pre></figure>

<p>Check out the <a href="https://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll’s GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.]]></summary></entry><entry><title type="html">Real world case study: U.S. Congress</title><link href="http://localhost:4000/Wikipedia-sentiment-analysis/case/study/2025/10/07/real-world-case-study.html" rel="alternate" type="text/html" title="Real world case study: U.S. Congress" /><published>2025-10-07T00:00:00-04:00</published><updated>2025-10-07T00:00:00-04:00</updated><id>http://localhost:4000/Wikipedia-sentiment-analysis/case/study/2025/10/07/real-world-case-study</id><content type="html" xml:base="http://localhost:4000/Wikipedia-sentiment-analysis/case/study/2025/10/07/real-world-case-study.html"><![CDATA[<p>Let’s use the tools we have to perform a real world study. We’ll be looking at the Wikipedia articles for all the current members of the United States congress. There are 532 members in total: 432 members of the House and 100 members of the Senate. After assembling a starting table with some basic information, I used analyze_csv to compute sentiment analysis metrics using the BERT, RoBERTa, and RoBERTuito models. Now we’re ready to use plotting utitlies to draw meaningful conclusions about the dataset. Let’s import the functions we’ll be using.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sentiment_plots</span> <span class="kn">import</span> <span class="n">plot_group</span><span class="p">,</span> <span class="n">plot_corrs</span>
</code></pre></div></div>

<p>Now let’s perform some group plots. We’ll look at all the models we used, and let’s also separate the data by party. I’m setting min_group_size to 3 because there are 2 Independent members in the Senate: we’re just interested in the two major parties for this analysis.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models</span><span class="o">=</span><span class="p">[</span><span class="s">'bert'</span><span class="p">,</span><span class="s">'roberta'</span><span class="p">,</span><span class="s">'robertuito'</span><span class="p">]</span>
<span class="n">input_filename</span><span class="o">=</span><span class="s">'congress_analysis.csv'</span>
<span class="n">label_cols</span><span class="o">=</span><span class="p">[</span><span class="s">'Party'</span><span class="p">]</span>
<span class="n">min_group_size</span><span class="o">=</span><span class="mi">3</span>
</code></pre></div></div>

<p>Now let’s look at all 5 group plotting metrics and see if we can identify any trends.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'avg_paragraph_percent'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
<span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'avg_article_prob'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
<span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'percent_most_common'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
<span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'percent_highest_weighted_vote'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
<span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'percent_highest_weighted_prob'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_5_0.png" alt="png" /></p>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_5_1.png" alt="png" /></p>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_5_2.png" alt="png" /></p>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_5_3.png" alt="png" /></p>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_5_4.png" alt="png" /></p>

<p>Interesting! There are several findings here. The first is that the vast majority of the Wikipedia articles were classified as neutral by the three methods that give a single label for each article (‘percent_most_common’,’percent_highest_weighted_vote’, and ‘percent_highest_weighted_prob’). This shouldn’t be too surprising since Wikipedia is supposed to adopt a neutral tone in its articles. However, the BERT model did find significantly more negative articles amongst Republicans than Democrats. Furthermore, all models identified higher negative sentiment and lower positive sentiment for Republicans compared to Democrats when looking at the averages of methods that give three values for each article (‘avg_paragraph_percent’ and ‘avg_article_prob’). Maybe you’re thinking that this is because there is a small number of very negative Republican articles that are skewing the sample, and that if they were removed the sentiment would look pretty similar for both parties. Let’s test that idea by considering only the articles that the BERT model classified as neutral using the ‘percent_highest_weighted_vote’ criterion.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">label_cols</span><span class="o">=</span><span class="p">[</span><span class="s">'Party'</span><span class="p">,</span><span class="s">'Sentiment with highest weighted vote, BERT'</span><span class="p">]</span>
<span class="n">label_values</span><span class="o">=</span><span class="p">[</span><span class="bp">True</span><span class="p">,[</span><span class="s">'Neutral'</span><span class="p">]]</span>
<span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'avg_paragraph_percent'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">label_values</span><span class="o">=</span><span class="n">label_values</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
<span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'avg_article_prob'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">label_values</span><span class="o">=</span><span class="n">label_values</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_7_0.png" alt="png" /></p>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_7_1.png" alt="png" /></p>

<p>From this result, we can see that the trend remains even after removing the negative articles. This suggests even for articles that are classified as neutral overall, articles about Republicans tend to contain more negative sentiment and less positive sentiment than those about their Democratic counterparts. Next, let’s see if there are any differences in sentiment between the House and the Senate. We’ll look at all 5 group metrics like we did before.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">label_cols</span><span class="o">=</span><span class="p">[</span><span class="s">'Chamber'</span><span class="p">]</span>

<span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'avg_paragraph_percent'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
<span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'avg_article_prob'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
<span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'percent_most_common'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
<span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'percent_highest_weighted_vote'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
<span class="n">plot_group</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">label_cols</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'percent_highest_weighted_prob'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_group_size</span><span class="o">=</span><span class="n">min_group_size</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_9_0.png" alt="png" /></p>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_9_1.png" alt="png" /></p>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_9_2.png" alt="png" /></p>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_9_3.png" alt="png" /></p>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_9_4.png" alt="png" /></p>

<p>Interestingly, most of the group metrics identify more negative sentiment amongst articles about Senators compared to those about House members. Let’s see if we can gain any more insight into this finding. One could hypothesize that the longer someone is in Congress, the more negative sentiment about them will be. Let’s plot the correlations between article sentiment probability and tenure length in years.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_col</span><span class="o">=</span><span class="s">'Tenure (years)'</span>
<span class="n">plot_corrs</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">x_col</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'article_prob'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_11_0.png" alt="png" /></p>

<p>This hypothesis seems to be falsified: there is no observable relationship between article sentiment probability and a Congress member’s length of tenure. Let’s do the same analysis again, but this time we’ll choose article length as our x variable instead of tenure length.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_col</span><span class="o">=</span><span class="s">'Article length (characters)'</span>
<span class="n">plot_corrs</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">x_col</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'article_prob'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_13_0.png" alt="png" /></p>

<p>These correlations are not incredibly strong but there’s definitely something here! It seems that as the length of the article increases, negative sentiment tends to increase while neutral sentiment tends to decrease. Positive sentiment seems to be completely unaffected. One explanation for this could be that for this dataset, all articles contain biographical sections (Early life, Education, etc.) that are highly neutral in tone. As article length increases, there will likely be more discussions of policy positions or controversies that contain negative sentiment. Going back to our discussion of sentiment for House vs. Senate members, let’s look at the average article length for both categories.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">input_filename</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'Chamber'</span><span class="p">)[</span><span class="s">'Article length (characters)'</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Chamber
House     11004.451389
Senate    27861.890000
Name: Article length (characters), dtype: float64
</code></pre></div></div>

<p>As we can see, the average Wikipedia article for a Senator is well over twice as long as the average Wikipedia article for a House member. Thus, it seems reasonable to conclude that Senators attract more negative sentiment because they’re more well-known than House members, and their longer articles will simply reflect the criticism that comes with greater notoriety. But wait, you ask: what if the reason that longer articles are more negative is <em>because</em> they’re about Senators, rather than articles about Senators being more negative because they’re longer? To address this concern, we should look at the trends within both the House and the Senate.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">filter_cols</span><span class="o">=</span><span class="p">[</span><span class="s">'Chamber'</span><span class="p">]</span>
<span class="n">filter_values</span><span class="o">=</span><span class="p">[[</span><span class="s">'House'</span><span class="p">]]</span>
<span class="n">plot_corrs</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">x_col</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'article_prob'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">filter_cols</span><span class="o">=</span><span class="n">filter_cols</span><span class="p">,</span><span class="n">filter_values</span><span class="o">=</span><span class="n">filter_values</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_17_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">filter_values</span><span class="o">=</span><span class="p">[[</span><span class="s">'Senate'</span><span class="p">]]</span>
<span class="n">plot_corrs</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">input_filename</span><span class="p">,</span><span class="n">x_col</span><span class="p">,</span><span class="n">plot_metric</span><span class="o">=</span><span class="s">'article_prob'</span><span class="p">,</span><span class="n">save_fig</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">filter_cols</span><span class="o">=</span><span class="n">filter_cols</span><span class="p">,</span><span class="n">filter_values</span><span class="o">=</span><span class="n">filter_values</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="Example4_real_world_study_files/Example4_real_world_study_18_0.png" alt="png" /></p>

<p>As we can see, the trends continue to exist even after separating by chamber, although they’re quite weak for the Senate outside of the BERT model. In any case, we can safely conclude that the trends of increasing negative sentiment and decreasing neutral sentiment with increasing article length are not caused by Senate articles simply being more negative and less neutral than House articles. Rather, it seems more likely that there is a general trend that as article length increases, negative sentiment increases and neutral sentiment decreases, and the differences in sentiment between House and Senate articles can be explained by this trend.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>]]></content><author><name></name></author><category term="case" /><category term="study" /><summary type="html"><![CDATA[Let’s use the tools we have to perform a real world study. We’ll be looking at the Wikipedia articles for all the current members of the United States congress. There are 532 members in total: 432 members of the House and 100 members of the Senate. After assembling a starting table with some basic information, I used analyze_csv to compute sentiment analysis metrics using the BERT, RoBERTa, and RoBERTuito models. Now we’re ready to use plotting utitlies to draw meaningful conclusions about the dataset. Let’s import the functions we’ll be using.]]></summary></entry></feed>