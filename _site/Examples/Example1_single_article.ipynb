{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e3f169-83ee-47aa-bfc0-43d2b793bde7",
   "metadata": {},
   "source": [
    "In this example notebook, we will see how to perform sentiment analysis on a single Wikipedia article using LLM models. First, we need to import the analyze_url function from wiki_analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbfc8ecc-0154-4348-bfca-68c2ef60736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiki_analysis import analyze_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa8cd2-2f10-4281-a586-172d2fe4e0a3",
   "metadata": {},
   "source": [
    "Next, we need to specify the URL of the Wikipedia page to analyze and the LLM models we wish to use. Optionally, we may specify the filename we wish to give to the output .csv file, the filepath where the .csv file will be saved, and whether or not to display job progress. For an example, let's look at Taylor Swift's Wikipedia article and perform sentiment analysis on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7475339a-22a6-4698-8cd6-cc259ee405dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://en.wikipedia.org/wiki/Taylor_Swift' #String containing the URL\n",
    "models=['bert','roberta','robertuito'] #String or list of strings. Available choices are 'bert','roberta','robertuito', and 'distilbert'.\n",
    "output_filename='Taylor_Swift_analysis.csv' #Filename for output csv file. Default is 'analysis.csv'\n",
    "output_path='path/to/my/file' #Filepath at which csv file is saved. If left unspecified, file will be saved in working location\n",
    "show_progress=True #Whether or not to display job progress. True by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37395356-51f7-4f48-baeb-cce21c3c08d8",
   "metadata": {},
   "source": [
    "Now that the inputs have been specified, we're ready to analyze! If show_progress=True, you will see job progress in terms of paragraphs. Occasionally, the listed number of paragraphs may increase: don't panic if this happens! It just means there was a long paragraph that needed to be split up in order to avoid violating the model token limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f767c631-78d2-4753-a0e0-ed9af6bd9387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/83 paragraphs analyzed\n",
      "2/83 paragraphs analyzed\n",
      "3/83 paragraphs analyzed\n",
      "4/83 paragraphs analyzed\n",
      "5/83 paragraphs analyzed\n",
      "6/83 paragraphs analyzed\n",
      "7/83 paragraphs analyzed\n",
      "8/83 paragraphs analyzed\n",
      "9/83 paragraphs analyzed\n",
      "10/83 paragraphs analyzed\n",
      "11/83 paragraphs analyzed\n",
      "12/83 paragraphs analyzed\n",
      "13/83 paragraphs analyzed\n",
      "14/83 paragraphs analyzed\n",
      "15/83 paragraphs analyzed\n",
      "16/83 paragraphs analyzed\n",
      "17/83 paragraphs analyzed\n",
      "18/83 paragraphs analyzed\n",
      "19/83 paragraphs analyzed\n",
      "20/83 paragraphs analyzed\n",
      "21/83 paragraphs analyzed\n",
      "22/83 paragraphs analyzed\n",
      "23/83 paragraphs analyzed\n",
      "24/83 paragraphs analyzed\n",
      "25/83 paragraphs analyzed\n",
      "26/83 paragraphs analyzed\n",
      "27/83 paragraphs analyzed\n",
      "28/83 paragraphs analyzed\n",
      "29/83 paragraphs analyzed\n",
      "30/83 paragraphs analyzed\n",
      "31/83 paragraphs analyzed\n",
      "32/83 paragraphs analyzed\n",
      "33/83 paragraphs analyzed\n",
      "34/83 paragraphs analyzed\n",
      "35/83 paragraphs analyzed\n",
      "36/83 paragraphs analyzed\n",
      "37/83 paragraphs analyzed\n",
      "38/83 paragraphs analyzed\n",
      "39/83 paragraphs analyzed\n",
      "40/83 paragraphs analyzed\n",
      "41/83 paragraphs analyzed\n",
      "42/83 paragraphs analyzed\n",
      "43/83 paragraphs analyzed\n",
      "44/83 paragraphs analyzed\n",
      "45/83 paragraphs analyzed\n",
      "46/83 paragraphs analyzed\n",
      "47/83 paragraphs analyzed\n",
      "48/83 paragraphs analyzed\n",
      "49/83 paragraphs analyzed\n",
      "50/83 paragraphs analyzed\n",
      "51/83 paragraphs analyzed\n",
      "52/83 paragraphs analyzed\n",
      "53/83 paragraphs analyzed\n",
      "54/83 paragraphs analyzed\n",
      "55/83 paragraphs analyzed\n",
      "56/83 paragraphs analyzed\n",
      "57/83 paragraphs analyzed\n",
      "58/83 paragraphs analyzed\n",
      "59/83 paragraphs analyzed\n",
      "60/83 paragraphs analyzed\n",
      "61/83 paragraphs analyzed\n",
      "62/83 paragraphs analyzed\n",
      "63/83 paragraphs analyzed\n",
      "64/83 paragraphs analyzed\n",
      "65/83 paragraphs analyzed\n",
      "66/83 paragraphs analyzed\n",
      "67/83 paragraphs analyzed\n",
      "68/83 paragraphs analyzed\n",
      "69/83 paragraphs analyzed\n",
      "70/83 paragraphs analyzed\n",
      "71/83 paragraphs analyzed\n",
      "72/83 paragraphs analyzed\n",
      "73/83 paragraphs analyzed\n",
      "74/83 paragraphs analyzed\n",
      "75/83 paragraphs analyzed\n",
      "76/83 paragraphs analyzed\n",
      "77/83 paragraphs analyzed\n",
      "78/83 paragraphs analyzed\n",
      "79/83 paragraphs analyzed\n",
      "80/83 paragraphs analyzed\n",
      "81/83 paragraphs analyzed\n",
      "82/83 paragraphs analyzed\n",
      "83/83 paragraphs analyzed\n"
     ]
    }
   ],
   "source": [
    "analyze_url(url,models,output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1575c-eb6e-40ee-8136-09338526f486",
   "metadata": {},
   "source": [
    "Now you should have the .csv file containing the analysis results! For each model, the captured results are the most common sentiment, sentiment with the highest weighted vote, sentiment with the highest weight probability, the weighted probability for each sentiment, the number of paragraphs for each sentiment, and the percent of paragraphs for each sentiment. The article length in number of characters is also recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a14b2b-7e3e-4697-b80f-f15e3a3b1131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
